{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7u6sEhC8nfWjeJgaifN7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmf/Cities_traffic/blob/main/Veveritele_salbatice_aad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup & Data Exploration"
      ],
      "metadata": {
        "id": "31SgFbt7ApcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "U6WwQiXww8mP",
        "outputId": "5bd19b7b-97a6-4bdc-93fa-fc960ff9c34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset URL: https://www.kaggle.com/datasets/tanishqdublish/urban-traffic-density-in-cities\n",
            "License(s): MIT\n",
            "urban-traffic-density-in-cities.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace /content/urban-traffic-data/futuristic_city_traffic.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/urban-traffic-data/Urban Traffic Density in Cities.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7844883ba6c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Step 4: Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Update the filename below as needed – check the contents of /content/urban-traffic-data/ for the correct CSV file name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/urban-traffic-data/Urban Traffic Density in Cities.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/urban-traffic-data/Urban Traffic Density in Cities.csv'"
          ]
        }
      ],
      "source": [
        "# Step 0: Setup - Mount Google Drive and Configure Kaggle API\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Set up Kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp '/content/drive/My Drive/kaggle/kaggle.json' ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Step 1: Download the Urban Traffic Density dataset\n",
        "!kaggle datasets download -d tanishqdublish/urban-traffic-density-in-cities -p /content/urban-traffic-data\n",
        "\n",
        "# Step 2: Unzip the downloaded files\n",
        "!unzip -q /content/urban-traffic-data/urban-traffic-density-in-cities.zip -d /content/urban-traffic-data\n",
        "\n",
        "# Step 3: Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 4: Load the dataset\n",
        "# Update the filename below as needed – check the contents of /content/urban-traffic-data/ for the correct CSV file name.\n",
        "df = pd.read_csv(\"/content/urban-traffic-data/Urban Traffic Density in Cities.csv\")\n",
        "\n",
        "\n",
        "# Quick exploration of the dataset\n",
        "print(\"First 5 records:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataframe Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning & Preprocessing"
      ],
      "metadata": {
        "id": "0t7FiHmuBeqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify missing values in each column\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Example: Fill missing numeric values (e.g., 'speed') with the median if needed\n",
        "if 'speed' in df.columns:\n",
        "    median_speed = df['speed'].median()\n",
        "    df['speed'].fillna(median_speed, inplace=True)\n",
        "\n",
        "# Check for duplicates and remove them\n",
        "num_duplicates = df.duplicated().sum()\n",
        "print(\"\\nNumber of duplicate records:\", num_duplicates)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Convert date/time column to datetime type (assuming the column is named 'time')\n",
        "if 'time' in df.columns:\n",
        "    df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "# Convert numeric columns explicitly (e.g., ensure 'speed' is numeric)\n",
        "if 'speed' in df.columns:\n",
        "    df['speed'] = pd.to_numeric(df['speed'], errors='coerce')"
      ],
      "metadata": {
        "id": "q-Axp0TaBi7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with Outliers"
      ],
      "metadata": {
        "id": "BSHDlD2BBznu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers for the 'speed' column using the IQR method\n",
        "if 'speed' in df.columns:\n",
        "    Q1 = df['speed'].quantile(0.25)\n",
        "    Q3 = df['speed'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    print(f\"\\nSpeed lower bound: {lower_bound}, upper bound: {upper_bound}\")\n",
        "\n",
        "    # Filter the dataset to only include values within the bounds\n",
        "    df = df[(df['speed'] >= lower_bound) & (df['speed'] <= upper_bound)]\n"
      ],
      "metadata": {
        "id": "IViiIRkuB4ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering & Sorting Data"
      ],
      "metadata": {
        "id": "ug79Tc1bB7QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering example: records for rainy weather (make sure the 'weather' column exists)\n",
        "if 'weather' in df.columns:\n",
        "    df_rainy = df[df['weather'].str.lower() == 'rainy']\n",
        "    print(\"\\nFirst few records for rainy weather:\")\n",
        "    print(df_rainy.head())\n",
        "\n",
        "# Filtering example: records where speed is greater than 50 (adjust threshold if needed)\n",
        "if 'speed' in df.columns:\n",
        "    df_speeding = df[df['speed'] > 50]\n",
        "    print(\"\\nRecords with speed > 50:\")\n",
        "    print(df_speeding.head())\n",
        "\n",
        "# Sorting the dataset by 'speed' in descending order\n",
        "if 'speed' in df.columns:\n",
        "    df_sorted = df.sort_values(by='speed', ascending=False)\n",
        "    print(\"\\nTop records sorted by speed (descending):\")\n",
        "    print(df_sorted.head())\n"
      ],
      "metadata": {
        "id": "BpadANp2CErs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping & Aggregation"
      ],
      "metadata": {
        "id": "AjPwuE-lCNnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by weather condition to calculate the average speed\n",
        "if 'weather' in df.columns and 'speed' in df.columns:\n",
        "    avg_speed_weather = df.groupby('weather')['speed'].mean()\n",
        "    print(\"\\nAverage speed by weather condition:\")\n",
        "    print(avg_speed_weather)\n",
        "\n",
        "# Grouping by hour to analyze traffic volume (requires that 'time' is a datetime column)\n",
        "if 'time' in df.columns:\n",
        "    traffic_volume_time = df.groupby(df['time'].dt.hour).size()\n",
        "    print(\"\\nTraffic volume by hour:\")\n",
        "    print(traffic_volume_time)\n",
        "\n",
        "# More detailed aggregation: min, max, mean speeds by weather condition\n",
        "if 'weather' in df.columns and 'speed' in df.columns:\n",
        "    summary = df.groupby('weather').agg({'speed': ['mean', 'max', 'min']})\n",
        "    print(\"\\nSpeed summary (mean, max, min) by weather condition:\")\n",
        "    print(summary)\n"
      ],
      "metadata": {
        "id": "DgROUvvECOxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis (EDA) & Visualization"
      ],
      "metadata": {
        "id": "qEka4su6CVBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 1: Distribution of speeds\n",
        "if 'speed' in df.columns:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    df['speed'].hist(bins=30)\n",
        "    plt.title(\"Speed Distribution\")\n",
        "    plt.xlabel(\"Speed\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "# Visualization 2: Boxplot of speed by weather condition\n",
        "if 'weather' in df.columns and 'speed' in df.columns:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(x='weather', y='speed', data=df)\n",
        "    plt.title(\"Speed by Weather Condition\")\n",
        "    plt.show()\n",
        "\n",
        "# Visualization 3: Traffic volume by hour (time-series analysis)\n",
        "if 'time' in df.columns:\n",
        "    traffic_hour = df.groupby(df['time'].dt.hour).size()\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    traffic_hour.plot(kind='line')\n",
        "    plt.title(\"Traffic Volume by Hour\")\n",
        "    plt.xlabel(\"Hour\")\n",
        "    plt.ylabel(\"Number of Records\")\n",
        "    plt.show()\n",
        "\n",
        "# Visualization 4: Correlation heatmap (only numerical features)\n",
        "numeric_cols = df.select_dtypes(include=[np.number])\n",
        "plt.figure(figsize=(8, 5))\n",
        "correlation = numeric_cols.corr()\n",
        "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BZUBc_J9CZzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}